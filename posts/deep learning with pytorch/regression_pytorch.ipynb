{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "## Tensor\n",
    "1. scalar: 0维，数字\n",
    "2. vector: 1维\n",
    "3. matrix: 2维\n",
    "4. tensor: 3维或更多\n",
    "\n",
    "为了简便起见，我们把vector和matrix也叫做tensor.  \n",
    "tensor()既能创建scalar也能创建tensor. Pytorch里的tensor和numpy很像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.5623,  1.2617, -0.7663, -0.4424],\n",
      "         [ 1.5027,  0.2160,  0.2078,  0.4431],\n",
      "         [ 1.1256, -0.0226,  1.0234, -1.1170]],\n",
      "\n",
      "        [[-1.4024,  0.5176,  0.5074,  0.5848],\n",
      "         [-1.1117,  0.4459,  0.6979,  0.9647],\n",
      "         [-0.1269,  0.0614, -1.0792,  0.4969]]])\n",
      "torch.Size([2, 3, 4]) torch.Size([2, 3, 4])\n",
      "torch.Size([3]) torch.Size([3])\n",
      "torch.Size([]) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "scalar = torch.tensor(3.14159)\n",
    "vector = torch.tensor([1,2,3])\n",
    "matrix = torch.ones((2,3), dtype=torch.float)\n",
    "tensor = torch.randn((2,3,4), dtype=torch.float)\n",
    "print(tensor)\n",
    "print(tensor.size(), tensor.shape)\n",
    "print(vector.size(), vector.shape)\n",
    "print(scalar.size(), scalar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 2., 1., 1., 1., 1.]])\n",
      "tensor([[1., 2., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "same_matrix = matrix.view(1,6)\n",
    "print(same_matrix)\n",
    "same_matrix[0,1]=2\n",
    "print(same_matrix)\n",
    "another_matrix = same_matrix.clone().detach() # duplicate the data\n",
    "print(another_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA\n",
    "我们可以用torch.as_tensor()很方便地把numpy数组转成tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dummy_array = np.array([1,2,3])\n",
    "dummy_tensor = torch.as_tensor(dummy_array)\n",
    "dummy_array[1]=0\n",
    "dummy_tensor\n",
    "# 注意这里是改引用而不是改拷贝。这也是我们不用torch.tensor()的原因"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上我们只是创建了CPU tensor，接下来我们使用GPU.显然GPU可以加速模型训练。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NVIDIA GeForce GTX 1060 6GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1, device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "# 把cpu tensor转成gpu tensor\n",
    "gpu_tensor = torch.as_tensor(dummy_array).to(device)\n",
    "gpu_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Data Generation\n",
    "true_b = 1\n",
    "true_w = 2\n",
    "N = 100\n",
    "np.random.seed(42)\n",
    "\n",
    "x = np.random.rand(N,1)\n",
    "epsilon = .1 * np.random.randn(N,1)\n",
    "y = true_b + true_w * x + epsilon\n",
    "\n",
    "# Split the synthetic data into train and validation sets.\n",
    "idx = np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "train_idx = idx[:int(N*.8)]\n",
    "val_idx = idx[int(N*.8):]\n",
    "x_train,y_train = x[train_idx],y[train_idx]\n",
    "x_val,y_val = x[val_idx,],y[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "x_train_tensor = torch.as_tensor(x_train).float().to(device)\n",
    "y_train_tensor = torch.as_tensor(y_train).float().to(device)\n",
    "print(type(x_train), type(x_train_tensor), x_train_tensor.type())\n",
    "# 用tensor_val.type()可以告诉你这是GPU tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# step0 - initialize parameters\n",
    "# 变量在创建时就指定好device\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(b,w)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1 - compute predictions, forward pass\n",
    "yhat = b + w * x_train_tensor \n",
    "\n",
    "# step2 - compute loss\n",
    "error = yhat - y_train_tensor\n",
    "loss = (error ** 2).mean()\n",
    "\n",
    "# step3 - compute gradients, no more manual computation\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True True\n",
      "False False\n",
      "tensor([-3.3881], device='cuda:0') tensor([-1.9439], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.], device='cuda:0'), tensor([0.], device='cuda:0'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(error.requires_grad, yhat.requires_grad, b.requires_grad, w.requires_grad)\n",
    "print(y_train_tensor.requires_grad, x_train_tensor.requires_grad)\n",
    "print(b.grad, w.grad)\n",
    "# 如果再次运行step1~3,梯度会被累积(差不多是x2),这是为了规避硬件限制，但这不是我们想要的。\n",
    "b.grad.zero_(), w.grad.zero_() # 放在step4之后，把gradients afterward置0\n",
    "# torch.no_grad() 可以让我们在不影响computation graph下执行python运算.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"222pt\" height=\"283pt\"\n",
       " viewBox=\"0.00 0.00 222.00 283.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 279)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-279 218,-279 218,4 -4,4\"/>\n",
       "<!-- 140321574379792 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140321574379792</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"139,-31 74,-31 74,0 139,0 139,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (80, 1)</text>\n",
       "</g>\n",
       "<!-- 140321573395456 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140321573395456</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-86 62,-86 62,-67 151,-67 151,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140321573395456&#45;&gt;140321574379792 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140321573395456&#45;&gt;140321574379792</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.5,-66.79C106.5,-60.07 106.5,-50.4 106.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110,-41.19 106.5,-31.19 103,-41.19 110,-41.19\"/>\n",
       "</g>\n",
       "<!-- 140321573394640 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140321573394640</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-141 0,-141 0,-122 101,-122 101,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140321573394640&#45;&gt;140321573395456 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140321573394640&#45;&gt;140321573395456</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.5,-121.98C67.69,-114.23 80.01,-102.58 89.97,-93.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"92.48,-95.59 97.34,-86.17 87.67,-90.5 92.48,-95.59\"/>\n",
       "</g>\n",
       "<!-- 140321574371472 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140321574371472</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-208 23.5,-208 23.5,-177 77.5,-177 77.5,-208\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 140321574371472&#45;&gt;140321573394640 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140321574371472&#45;&gt;140321573394640</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.92C50.5,-169.22 50.5,-159.69 50.5,-151.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.25 50.5,-141.25 47,-151.25 54,-151.25\"/>\n",
       "</g>\n",
       "<!-- 140321573389648 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140321573389648</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-141 119,-141 119,-122 208,-122 208,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 140321573389648&#45;&gt;140321573395456 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140321573389648&#45;&gt;140321573395456</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M154.34,-121.98C146,-114.23 133.47,-102.58 123.32,-93.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.53,-90.42 115.82,-86.17 120.76,-95.54 125.53,-90.42\"/>\n",
       "</g>\n",
       "<!-- 140321573390416 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140321573390416</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"214,-202 113,-202 113,-183 214,-183 214,-202\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-190\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140321573390416&#45;&gt;140321573389648 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140321573390416&#45;&gt;140321573389648</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.5,-182.79C163.5,-174.6 163.5,-162.06 163.5,-151.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167,-151.24 163.5,-141.24 160,-151.24 167,-151.24\"/>\n",
       "</g>\n",
       "<!-- 140321572672336 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140321572672336</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"190.5,-275 136.5,-275 136.5,-244 190.5,-244 190.5,-275\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-251\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 140321572672336&#45;&gt;140321573390416 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140321572672336&#45;&gt;140321573390416</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.5,-243.75C163.5,-234.39 163.5,-222.19 163.5,-212.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167,-212.02 163.5,-202.02 160,-212.02 167,-212.02\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f9f29895270>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "# step0\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "# step1\n",
    "yhat = b + w * x_train_tensor\n",
    "# step2\n",
    "error = yhat - y_train_tensor\n",
    "loss = (error ** 2).mean()\n",
    "# plotting the graph\n",
    "make_dot(yhat)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算图\n",
    "蓝框是我们所使用的tensor参数(左b右w)，灰框(MulBackward0 AddBackward0)是梯度计算($w*x, b+w*x$)，绿框backward()所需的tensor.\n",
    "## Optimizer\n",
    "两个参数我们可以手动更新，但有大量的参数时呢？就需要optimizer,SGD是最基本的optimizer.\n",
    "```python\n",
    "optimizer = torch.optim.SGD([b,w], lr=lr)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "# step0 - initialize parameters b and w\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "# define a SGD optimizer to update parameters\n",
    "optimizer = torch.optim.SGD([b,w], lr=lr)\n",
    "\n",
    "n_epochs = 1000\n",
    "for epoch in range(n_epochs):\n",
    "    # step1 - computes predictions\n",
    "    yhat = b + w * x_train_tensor\n",
    "    # step2 - computes loss\n",
    "    error = yhat - y_train_tensor\n",
    "    loss = (error ** 2).mean()\n",
    "    # step3 - computes gradients\n",
    "    loss.backward()\n",
    "    # step4 - updates parameters\n",
    "    optimizer.step()\n",
    "    # no more b-=lr*b.grad and w-=lr*w.grad\n",
    "    optimizer.zero_grad()\n",
    "    # no more b.grad.zero_() and w.grad.zero_()\n",
    "\n",
    "print(b,w)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss\n",
    "```python\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "# step0 - initialize parameters b and w\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "# define a SGD optimizer to update parameters\n",
    "optimizer = torch.optim.SGD([b,w], lr=lr)\n",
    "# define MSE loss function\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "n_epochs = 1000\n",
    "for epoch in range(n_epochs):\n",
    "    # step1 - computes predictions\n",
    "    yhat = b + w * x_train_tensor\n",
    "    # step2 - computes loss\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "    # step3 - computes gradients\n",
    "    loss.backward()\n",
    "    # step4 - updates parameters\n",
    "    optimizer.step()\n",
    "    # no more b-=lr*b.grad and w-=lr*w.grad\n",
    "    optimizer.zero_grad()\n",
    "    # no more b.grad.zero_() and w.grad.zero_()\n",
    "\n",
    "print(b,w)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {0: {'momentum_buffer': None}, 1: {'momentum_buffer': None}},\n",
       " 'param_groups': [{'lr': 0.1,\n",
       "   'momentum': 0,\n",
       "   'dampening': 0,\n",
       "   'weight_decay': 0,\n",
       "   'nesterov': False,\n",
       "   'maximize': False,\n",
       "   'foreach': None,\n",
       "   'differentiable': False,\n",
       "   'params': [0, 1]}]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ManualLinearRegression(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.b = torch.nn.Parameter(torch.randn(1,requires_grad=True,dtype=torch.float))\n",
    "        self.w = torch.nn.Parameter(torch.randn(1,requires_grad=True,dtype=torch.float))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.b + self.w * x\n",
    "\n",
    "dummy = ManualLinearRegression()\n",
    "list(dummy.parameters())\n",
    "dummy.state_dict()\n",
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('b', tensor([1.0235], device='cuda:0')), ('w', tensor([1.9690], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "# step0 - initialize parameters\n",
    "torch.manual_seed(42)\n",
    "model = ManualLinearRegression().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "n_epochs = 1000\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    # step1 computes predictions\n",
    "    yhat = model(x_train_tensor)\n",
    "    # step2 - computes loss\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "    # step3 - computes gradients\n",
    "    loss.backward()\n",
    "    # step4 - updates parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (layer1): Linear(in_features=3, out_features=5, bias=True)\n",
       "  (layer2): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = torch.nn.Linear(1,1)\n",
    "linear\n",
    "linear.state_dict()\n",
    "\n",
    "model = torch.nn.Sequential()\n",
    "model.add_module('layer1', torch.nn.Linear(3,5))\n",
    "model.add_module('layer2', torch.nn.Linear(5,1))\n",
    "model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data_preparation/v0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_preparation/v0.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "x_train_tensor = torch.as_tensor(x_train).float().to(device)\n",
    "y_train_tensor = torch.as_tensor(y_train).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model_configuration/v0.py\n",
    "\n",
    "lr = 0.1\n",
    "torch.manual_seed(42)\n",
    "model = n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
